{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43971c-67db-4a4e-a3c9-b8c7ba797732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from utils import *\n",
    "from dataset_loader import *\n",
    "\n",
    "from unet import Unet\n",
    "from diffusion import GaussianDiffusion\n",
    "from embedding import ConditionalEmbedding\n",
    "from scheduler import GradualWarmupScheduler\n",
    "from mine.mine import Mine, T\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3c5e1-d096-4307-ad1f-ecfd51eec459",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa9568-552c-458c-9505-87edc1f6338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.gpu_id = 0\n",
    "        self.batch_size = 128\n",
    "        self.num_public_attr = 4 # number of public attribute classes (i.e., gender)\n",
    "        self.num_private_attr = 2 # number of private attribute classes (i.e., gender)\n",
    "        self.dataset = 'motion' # 'mobi', 'motion', 'wifi'\n",
    "        self.private = 'gender' # 'weight', 'gender', 'height'\n",
    "        self.epochs = 90\n",
    "        self.train_surrogate = False\n",
    "        self.seed = 102\n",
    "        self.verbose = 1 # for Keras-based evaluation models\n",
    "\n",
    "args = Args()\n",
    "# args = args_parser()\n",
    "\n",
    "if args.dataset == 'mobi':\n",
    "    if args.private == 'weight':\n",
    "        args.num_private_attr = 3\n",
    "    elif args.private == 'gender':\n",
    "        args.num_private_attr = 2\n",
    "elif args.dataset == 'motion':\n",
    "    args.num_private_attr = 2\n",
    "elif args.dataset == 'wifi':\n",
    "    args.batch_size = 8\n",
    "    args.num_private_attr = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7be27-da8c-4139-bca8-13d8b9b948ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "if args.gpu_id >= 0:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_id)\n",
    "    cuda_id = \"cuda:\" + str(0)\n",
    "\n",
    "device = torch.device(cuda_id if torch.cuda.is_available() else \"cpu\")\n",
    "if (torch.cuda.is_available()):\n",
    "    torch.cuda.set_device(cuda_id)\n",
    "    print(\"Current GPU ID:\", torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6509a3ff-c497-4bdd-a2ce-7b8444ecf5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionArgs:\n",
    "    def __init__(self):\n",
    "        self.inch = 1 # input channels for Unet model\n",
    "        self.modch = 256 # model channels for Unet model\n",
    "        self.T = 1000  # timesteps for Unet model\n",
    "        self.outch = 1 # output channels for Unet model\n",
    "        self.chmul = [1,2] # [1,2,2,2] # architecture parameters training Unet model\n",
    "        self.numres = 2 # number of resblocks for each block in Unet model\n",
    "        self.cdim = 60 # dimension of conditional embedding\n",
    "        self.useconv = True # whether use convlution in downsample\n",
    "        self.droprate = 0.1 # dropout rate for model\n",
    "        self.dtype = torch.float32\n",
    "        self.lr = 2e-4 # learning rate\n",
    "        self.w1 = 1.8 # hyperparameters for classifier-free guidance strength\n",
    "        self.v = 0.1 # hyperparameters for the variance of posterior distribution\n",
    "        self.epoch = 80 # epochs for training\n",
    "        self.multiplier = 2 # multiplier for warmup\n",
    "        self.threshold = 0.3 # threshold for classifier-free guidance\n",
    "        self.interval = 4 # epoch interval between two evaluations\n",
    "        self.moddir = './models/privdiffuser_'+args.dataset+'_'+str(trial) # model addresses\n",
    "        # self.samdir = 'privdiffuser_sample' # sample addresses\n",
    "        self.genbatch = 80 # batch size for sampling process\n",
    "        # self.clsnum = 4 # 10 # num of label classes\n",
    "        self.num_steps = 50 # sampling steps for DDIM\n",
    "        self.eta = 0 # eta for variance during DDIM sampling process\n",
    "        self.select = 'linear' # selection stragies for DDIM\n",
    "        self.ddim = True # whether to use ddim\n",
    "        self.local_rank = -1 # node rank for distributed training\n",
    "        self.gpu_id = args.gpu_id\n",
    "        self.w2 = 0.0 # hyperparameters for negative classifier guidance strength\n",
    "        \n",
    "diff_args = DiffusionArgs()\n",
    "\n",
    "if args.dataset == 'wifi':\n",
    "    diff_args.useconv = False\n",
    "    diff_args.epoch = 28\n",
    "elif args.dataset == 'mobi':\n",
    "    diff_args.useconv = True\n",
    "    diff_args.epoch = 28\n",
    "    diff_args.modch=64\n",
    "elif args.dataset == 'motion':\n",
    "    diff_args.epoch = 80 \n",
    "    diff_args.interval = 8\n",
    "\n",
    "if not os.path.exists(diff_args.moddir):\n",
    "    os.makedirs(diff_args.moddir)\n",
    "    print(\"Mod dir created.\")\n",
    "else:\n",
    "    print(\"Mod dir already exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c1203-08fa-41eb-a7c5-a572342d3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "if args.dataset == 'mobi':\n",
    "    x_train, x_test, activity_train_label, activity_test_label, gender_train_label, gender_test_label, weight_train_label, weight_test_label, user_groups, user_groups_test, id_train, id_test = load_mobiact(args)\n",
    "elif args.dataset == 'motion':\n",
    "    x_train, x_test, activity_train_label, activity_test_label, gender_train_label, gender_test_label, user_groups, user_groups_test, id_train, id_test = load_motionsense()\n",
    "elif args.dataset == 'wifi':\n",
    "    x_train, x_test, activity_train_label, activity_test_label, weight_train_label, weight_test_label, height_train_label, height_test_label, user_groups, user_groups_test, id_train, id_test = load_wifi(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501c347-b129-441b-9d7c-e44ce0a9330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "x_train_tensor = torch.from_numpy(x_train.astype('float32'))\n",
    "x_test_tensor = torch.from_numpy(x_test.astype('float32'))\n",
    "\n",
    "x_train_tensor = torch.permute(x_train_tensor, (0,3,1,2))\n",
    "x_test_tensor = torch.permute(x_test_tensor, (0,3,1,2))\n",
    "\n",
    "act_train_tensor = torch.from_numpy(np.argmax(activity_train_label, axis=1))\n",
    "act_test_tensor = torch.from_numpy(np.argmax(activity_test_label, axis=1))\n",
    "\n",
    "if args.dataset == 'mobi':\n",
    "    gen_train_tensor = torch.from_numpy(np.argmax(gender_train_label, axis=1))\n",
    "    weight_train_tensor = torch.from_numpy(np.argmax(weight_train_label, axis=1))\n",
    "    train_dataset = TensorDataset(x_train_tensor, act_train_tensor, gen_train_tensor, weight_train_tensor)\n",
    "elif args.dataset == 'wifi':\n",
    "    height_train_tensor = torch.from_numpy(np.argmax(height_train_label, axis=1))\n",
    "    weight_train_tensor = torch.from_numpy(np.argmax(weight_train_label, axis=1))\n",
    "    train_dataset = TensorDataset(x_train_tensor, act_train_tensor, height_train_tensor, weight_train_tensor)\n",
    "elif args.dataset == 'motion':\n",
    "    gen_train_tensor = torch.from_numpy(np.argmax(gender_train_label, axis=1))\n",
    "    train_dataset = TensorDataset(x_train_tensor, act_train_tensor, gen_train_tensor)\n",
    "    \n",
    "data_train_loader = list(torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ec8262-f69f-4cfa-8909-8cda6bd50e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'mobi':\n",
    "    surrogate_train_dataset = TensorDataset(torch.permute(torch.from_numpy(x_train.astype('float32')), (0,3,1,2)), torch.from_numpy(activity_train_label))\n",
    "    surrogate_test_dataset = TensorDataset(torch.permute(torch.from_numpy(x_test.astype('float32')), (0,3,1,2)), torch.from_numpy(activity_test_label), torch.from_numpy(gender_test_label), torch.from_numpy(weight_test_label))\n",
    "    if args.private == 'gender':\n",
    "        priv_train_dataset = TensorDataset(torch.permute(torch.from_numpy(x_train.astype('float32')), (0,3,1,2)), torch.from_numpy(gender_train_label), torch.from_numpy(activity_train_label))\n",
    "    elif args.private == 'weight':\n",
    "        priv_train_dataset = TensorDataset(torch.permute(torch.from_numpy(x_train.astype('float32')), (0,3,1,2)), torch.from_numpy(weight_train_label), torch.from_numpy(activity_train_label))\n",
    "    else:\n",
    "        raise ValueError('Private attribute not found:', args.private, 'in dataset:', args.dataset)\n",
    "\n",
    "elif args.dataset == 'wifi':\n",
    "    surrogate_train_dataset = TensorDataset(torch.permute(torch.from_numpy(x_train.astype('float32')), (0,3,1,2)), torch.from_numpy(activity_train_label))\n",
    "    surrogate_test_dataset = TensorDataset(torch.permute(torch.from_numpy(x_test.astype('float32')), (0,3,1,2)), torch.from_numpy(activity_test_label), torch.from_numpy(height_test_label), torch.from_numpy(weight_test_label))\n",
    "    if args.private == 'height':\n",
    "        priv_train_dataset = TensorDataset(torch.permute(torch.from_numpy(x_train.astype('float32')), (0,3,1,2)), torch.from_numpy(height_train_label), torch.from_numpy(activity_train_label))\n",
    "    elif args.private == 'weight':\n",
    "        priv_train_dataset = TensorDataset(torch.permute(torch.from_numpy(x_train.astype('float32')), (0,3,1,2)), torch.from_numpy(weight_train_label), torch.from_numpy(activity_train_label))\n",
    "    else: \n",
    "        raise ValueError('Private attribute not found:', args.private, 'in dataset:', args.dataset)\n",
    "\n",
    "elif args.dataset == 'motion':\n",
    "    surrogate_train_dataset = TensorDataset(torch.permute(torch.from_numpy(x_train.astype('float32')), (0,3,1,2)), torch.from_numpy(activity_train_label))\n",
    "    surrogate_test_dataset = TensorDataset(torch.permute(torch.from_numpy(x_test.astype('float32')), (0,3,1,2)), torch.from_numpy(activity_test_label), torch.from_numpy(gender_test_label))\n",
    "    if args.private == 'gender':\n",
    "        priv_train_dataset = TensorDataset(torch.permute(torch.from_numpy(x_train.astype('float32')), (0,3,1,2)), torch.from_numpy(gender_train_label), torch.from_numpy(activity_train_label))\n",
    "    else:\n",
    "        raise ValueError('Private attribute not found:', args.private, 'in dataset:', args.dataset)\n",
    "\n",
    "else:\n",
    "    raise ValueError('Dataset not found:', args.dataset)\n",
    "\n",
    "surrogate_train_loader = list(torch.utils.data.DataLoader(surrogate_train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True))\n",
    "surrogate_test_loader = list(torch.utils.data.DataLoader(surrogate_test_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True))\n",
    "priv_train_loader = list(torch.utils.data.DataLoader(priv_train_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1324b61-5a54-40b8-91e7-22199c78cf80",
   "metadata": {},
   "source": [
    "## Surrogate Utility Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be601c38-2180-4a4b-b3c1-c56936aeadc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Surrogate_Utility_Classifier(nn.Module):\n",
    "    def __init__(self, num_classes, z_dim):\n",
    "        super(Surrogate_Utility_Classifier, self).__init__()\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "\n",
    "        if args.dataset == 'mobi':\n",
    "            self.fc1 = torch.nn.Conv2d(1, 8, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc2 = torch.nn.Conv2d(8, 16, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc3 = nn.Linear(16640, 512)\n",
    "        elif args.dataset == 'wifi':\n",
    "            self.fc1 = torch.nn.Conv2d(1, 16, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc2 = torch.nn.Conv2d(16, 32, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc3 = nn.Linear(241408, 512) # b8\n",
    "        elif args.dataset == 'motion':\n",
    "            self.fc1 = torch.nn.Conv2d(1, 64, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc2 = torch.nn.Conv2d(64, 128, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc3 = nn.Linear(66560, 512) # 64 128\n",
    "            \n",
    "        self.fc4 = nn.Linear(512, 128)\n",
    "        self.fc5 = nn.Linear(128, z_dim)\n",
    "        self.fc6 = nn.Linear(z_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        h2 = self.flatten(self.relu(self.fc2(h1)))\n",
    "        h3 = self.relu(self.fc3(h2))\n",
    "        h4 = self.relu(self.fc4(h3))\n",
    "        h5 = self.relu(self.fc5(h4))\n",
    "        z = torch.nn.functional.normalize(h5, dim=-1)\n",
    "        h6 = self.fc6(z)\n",
    "        return h6, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11857360-48ed-4a79-8b0f-779a3d065f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pub_classifier(model, trainloader, optimizer, epochs, model_path, device):\n",
    "    print(model_path)\n",
    "    model.train()\n",
    "    criterion_base = torch.nn.BCELoss()\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0     \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            logits, feature = model(inputs)\n",
    "            outputs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            loss = criterion_base(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "    # Save trained models\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    print('Surrogate Utility Model Training Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d0a47-11a3-4464-817d-d46a2612d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pub_classifier(args, model, testloader, pub_attr, device):  \n",
    "    # pub_attr: True or False, specify if this aux classifier is for public attribute or private attribute\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    labs_pred = np.array([])\n",
    "    labs_raw = np.array([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            if args.dataset == 'mobi':\n",
    "                images, act_labs, gen_labs, weight_labs = data\n",
    "                if pub_attr:\n",
    "                    labels = act_labs.to(device)\n",
    "                else:\n",
    "                    if args.private == 'gender':\n",
    "                        labels = gen_labs.to(device)\n",
    "                    elif args.private == 'weight':\n",
    "                        labels = weight_labs.to(device)\n",
    "            elif args.dataset == 'wifi':\n",
    "                images, act_labs, height_labs, weight_labs = data\n",
    "                if pub_attr:\n",
    "                    labels = act_labs.to(device)\n",
    "                else:\n",
    "                    if args.private == 'height':\n",
    "                        labels = height_labs.to(device)\n",
    "                    elif args.private == 'weight':\n",
    "                        labels = weight_labs.to(device)\n",
    "            elif args.dataset == 'motion':\n",
    "                images, act_labs, gen_labs = data\n",
    "                if pub_attr:\n",
    "                    labels = act_labs.to(device)\n",
    "                else:\n",
    "                    labels = gen_labs.to(device)        \n",
    "    \n",
    "            images = images.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            logits, feature = model(images)\n",
    "            outputs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            labs_pred = np.concatenate((labs_pred, predicted.detach().cpu().numpy()), axis=0 )\n",
    "            labs_raw = np.concatenate((labs_raw, torch.argmax(labels, dim=1).detach().cpu().numpy()), axis=0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "    print(\"Dataset:\", args.dataset)\n",
    "    if pub_attr:\n",
    "        print(\"Public Attr: Activity\")\n",
    "    else:\n",
    "        print(\"Private Attr:\", args.private)\n",
    "    print(f'Test Accuracy: {100 * correct / total} %')\n",
    "    print_accu_confmat_f1score(Y_true=labs_raw, Y_pred=labs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565b431-4caf-4d6a-b60c-c36f567540e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_model = Surrogate_Utility_Classifier(args.num_public_attr, diff_args.cdim)\n",
    "surrogate_model = surrogate_model.to(device)\n",
    "\n",
    "optimizer_pub = Adam(surrogate_model.parameters(), lr=2e-4)\n",
    "PATH_PUB = diff_args.moddir+'/pub_classifier_'+args.dataset+'_'+str(trial)+'.pt'\n",
    "print(PATH_PUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56116c4e-6d58-420f-9d0c-66c061e17bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_pub = True\n",
    "train_pub = False\n",
    "\n",
    "if args.dataset == 'mobi':\n",
    "    pub_epochs = 15\n",
    "elif args.dataset == 'wifi':\n",
    "    pub_epochs = 25\n",
    "elif args.dataset == 'motion':\n",
    "    pub_epochs = 80\n",
    "    \n",
    "if train_pub:\n",
    "    train_pub_classifier(surrogate_model, surrogate_train_loader, optimizer_pub, pub_epochs, PATH_PUB, device)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b65d7ea-b632-47d4-be30-324e14461f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not train_pub:\n",
    "    surrogate_model.load_state_dict(torch.load(PATH_PUB, map_location=torch.device('cpu')))\n",
    "    surrogate_model.to(device)\n",
    "eval_pub_classifier(args, surrogate_model, surrogate_test_loader, True, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb0bce-bf91-4e9d-bf36-38621c8e6f1d",
   "metadata": {},
   "source": [
    "## Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60c7af-bd2e-49ab-bcae-9926d32da93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert diff_args.genbatch % (torch.cuda.device_count() * diff_args.clsnum) == 0 , 'please re-set your genbatch!!!'\n",
    "\n",
    "# load data\n",
    "dataloader = data_train_loader\n",
    "\n",
    "# initialize models\n",
    "net = Unet(\n",
    "    in_ch = diff_args.inch,\n",
    "    mod_ch = diff_args.modch,\n",
    "    out_ch = diff_args.outch,\n",
    "    ch_mul = diff_args.chmul,\n",
    "    num_res_blocks = diff_args.numres,\n",
    "    cdim = diff_args.cdim,\n",
    "    use_conv = diff_args.useconv,\n",
    "    droprate = diff_args.droprate,\n",
    "    dtype = diff_args.dtype\n",
    ")\n",
    "\n",
    "betas = get_named_beta_schedule(num_diffusion_timesteps = diff_args.T)\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    dtype = diff_args.dtype,\n",
    "    model = net,\n",
    "    betas = betas,\n",
    "    w = diff_args.w1,\n",
    "    v = diff_args.v,\n",
    "    device = device\n",
    ")\n",
    "\n",
    "cemblayer = ConditionalEmbedding(10, diff_args.cdim, diff_args.cdim).to(device)\n",
    "\n",
    "# load last epoch\n",
    "lastpath = os.path.join(diff_args.moddir,'last_epoch.pt')\n",
    "if os.path.exists(lastpath):\n",
    "    lastepc = torch.load(lastpath)['last_epoch']\n",
    "    # load checkpoints\n",
    "    checkpoint = torch.load(os.path.join(diff_args.moddir, f'ckpt_{lastepc}_checkpoint.pt'), map_location='cpu')\n",
    "    net.load_state_dict(checkpoint['net'])\n",
    "    cemblayer.load_state_dict(checkpoint['cemblayer'])\n",
    "else:\n",
    "    lastepc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88339849-b037-42b5-a044-79340d57edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer settings\n",
    "optimizer = torch.optim.AdamW(\n",
    "    itertools.chain(\n",
    "        diffusion.model.parameters(),\n",
    "        cemblayer.parameters()\n",
    "    ),\n",
    "    lr = diff_args.lr,\n",
    "    weight_decay = 1e-4\n",
    ")\n",
    "\n",
    "cosineScheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer = optimizer,\n",
    "    T_max = diff_args.epoch,\n",
    "    eta_min = 0,\n",
    "    last_epoch = -1\n",
    ")\n",
    "\n",
    "warmUpScheduler = GradualWarmupScheduler(\n",
    "    optimizer = optimizer,\n",
    "    multiplier = diff_args.multiplier,\n",
    "    warm_epoch = diff_args.epoch // 10,\n",
    "    after_scheduler = cosineScheduler,\n",
    "    last_epoch = lastepc\n",
    ")\n",
    "\n",
    "if lastepc != 0:\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    warmUpScheduler.load_state_dict(checkpoint['scheduler'])\n",
    "    \n",
    "# training\n",
    "# cnt = torch.cuda.device_count()\n",
    "cnt = 1\n",
    "\n",
    "mean_losses = []\n",
    "\n",
    "for epc in range(lastepc, diff_args.epoch):\n",
    "    # turn into train mode\n",
    "    diffusion.model.train()\n",
    "    cemblayer.train()\n",
    "    running_loss = 0.0\n",
    "    num_batch = 0\n",
    "    with tqdm(dataloader, dynamic_ncols=True, disable=False) as tqdmDataLoader:\n",
    "        for img, *other in tqdmDataLoader:\n",
    "            b = img.shape[0]\n",
    "            optimizer.zero_grad()\n",
    "            x_0 = img.to(device)\n",
    "            num_batch += 1\n",
    "\n",
    "            output, emb = surrogate_model(x_0)\n",
    "            \n",
    "            cemb = cemblayer(emb.detach())\n",
    "            cemb[np.where(np.random.rand(b)<diff_args.threshold)] = 0\n",
    "            loss = diffusion.trainloss(x_0, cemb = cemb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            tqdmDataLoader.set_postfix(\n",
    "                ordered_dict={\n",
    "                    \"epoch\": epc + 1,\n",
    "                    \"loss\": loss.item(),\n",
    "                    \"batch per device\":x_0.shape[0],\n",
    "                    \"img shape\": x_0.shape[1:],\n",
    "                    \"LR\": optimizer.state_dict()['param_groups'][0][\"lr\"]\n",
    "                }\n",
    "            )\n",
    "    warmUpScheduler.step()\n",
    "    \n",
    "    print(f'[{epc + 1}, loss: {running_loss / num_batch:.3f}')\n",
    "    mean_losses.append(running_loss / num_batch)\n",
    "    \n",
    "    # save checkpoints\n",
    "    if (epc + 1) % diff_args.interval == 0:\n",
    "        checkpoint = {\n",
    "            'net':diffusion.model.state_dict(),\n",
    "            'cemblayer':cemblayer.state_dict(),\n",
    "            'optimizer':optimizer.state_dict(),\n",
    "            'scheduler':warmUpScheduler.state_dict()\n",
    "        }\n",
    "        torch.save({'last_epoch':epc+1}, os.path.join(diff_args.moddir,'last_epoch.pt'))\n",
    "        torch.save(checkpoint, os.path.join(diff_args.moddir, f'ckpt_{epc+1}_checkpoint.pt'))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c460e70-cbc1-4333-b67d-e2eff00fed36",
   "metadata": {},
   "source": [
    "## Aux Privacy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a2d9b4-066c-4ed1-8fd8-598ac661757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aux_Priv_Classifier(nn.Module):\n",
    "    def __init__(self, num_classes, z_dim):\n",
    "        super(Aux_Priv_Classifier, self).__init__()\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        \n",
    "        if args.dataset == 'mobi':\n",
    "            self.fc1 = torch.nn.Conv2d(1, 8, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc2 = torch.nn.Conv2d(8, 16, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc3 = nn.Linear(16640+diff_args.cdim, 512)\n",
    "        elif args.dataset == 'wifi':\n",
    "            self.fc1 = torch.nn.Conv2d(1, 16, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc2 = torch.nn.Conv2d(16, 32, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc3 = nn.Linear(241408+diff_args.cdim, 512) # b8\n",
    "        elif args.dataset == 'motion':\n",
    "            self.fc1 = torch.nn.Conv2d(1, 64, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc2 = torch.nn.Conv2d(64, 128, kernel_size=2, stride=1, padding=1)\n",
    "            self.fc3 = nn.Linear(66560+diff_args.cdim, 512)\n",
    "            \n",
    "        self.fc4 = nn.Linear(512, 128)\n",
    "        self.fc5 = nn.Linear(128, z_dim)\n",
    "        self.fc6 = nn.Linear(z_dim, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, emb):\n",
    "        h1 = self.relu(self.fc1(x))\n",
    "        h2 = self.flatten(self.relu(self.fc2(h1)))      \n",
    "        h2 = torch.cat((h2, emb), dim=1)\n",
    "        h3 = self.relu(self.fc3(h2))\n",
    "        h4 = self.relu(self.fc4(h3))\n",
    "        h5 = self.relu(self.fc5(h4))\n",
    "        z = torch.nn.functional.normalize(h5, dim=-1)\n",
    "        h6 = self.fc6(z)\n",
    "        return h6, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249690a8-21a4-4688-b29b-f616734999cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_priv_classifier(priv_model, surrogate_model, trainloader, optimizer, optimizer_mine, mi_estimator, w3, epochs, model_path, device):\n",
    "    priv_model.train()\n",
    "    criterion_base = torch.nn.BCELoss()\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        running_cls_loss = 0.0\n",
    "        running_mi_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels, pub_labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pub_labels = pub_labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_mine.zero_grad()\n",
    "\n",
    "            # condition private classifier on z_p\n",
    "            with torch.no_grad():\n",
    "                _output, emb = surrogate_model(inputs)\n",
    "\n",
    "            logits, feature = priv_model(inputs, emb)\n",
    "\n",
    "            # train mi_estimator separately due to the reversed loss\n",
    "            mi_train_loss = mi_estimator(pub_labels, feature.detach())\n",
    "            mi_train_loss.backward()\n",
    "            optimizer_mine.step()\n",
    "            outputs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            \n",
    "            cls_loss = criterion_base(outputs, labels)\n",
    "            mi_loss = mi_estimator(pub_labels, feature)\n",
    "            loss = cls_loss - w3 * mi_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(priv_model.parameters(), 1)\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            running_cls_loss += cls_loss.item()\n",
    "            running_mi_loss += mi_loss.item()\n",
    "            if i % 100 == 99:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}', f'cls_loss: {running_cls_loss / 100:.3f}', f'mi_loss: {running_mi_loss / 100:.3f}')\n",
    "                running_loss = 0.0\n",
    "                running_cls_loss = 0.0\n",
    "                running_mi_loss = 0.0\n",
    "\n",
    "    # Save trained models\n",
    "    torch.save(priv_model.state_dict(), model_path)\n",
    "    print('Auxiliary Privacy Classifier Training Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff10e00-64c1-466c-9053-4153a54d651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pub_attr: True or False, specify if this aux classifier is for public attribute or private attribute\n",
    "def eval_priv_classifier(args, priv_model, surrogte_model, testloader, pub_attr, device):  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    labs_pred = np.array([])\n",
    "    labs_raw = np.array([])\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    priv_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            if args.dataset == 'mobi':\n",
    "                images, act_labs, gen_labs, weight_labs = data\n",
    "                if pub_attr:\n",
    "                    labels = act_labs.to(device)\n",
    "                else:\n",
    "                    if args.private == 'gender':\n",
    "                        labels = gen_labs.to(device)\n",
    "                    elif args.private == 'weight':\n",
    "                        labels = weight_labs.to(device)\n",
    "    \n",
    "            elif args.dataset == 'wifi':\n",
    "                images, act_labs, height_labs, weight_labs = data\n",
    "                if pub_attr:\n",
    "                    labels = act_labs.to(device)\n",
    "                else:\n",
    "                    if args.private == 'height':\n",
    "                        labels = height_labs.to(device)\n",
    "                    elif args.private == 'weight':\n",
    "                        labels = weight_labs.to(device)\n",
    "    \n",
    "            elif args.dataset == 'motion':\n",
    "                images, act_labs, gen_labs = data\n",
    "                if pub_attr:\n",
    "                    labels = act_labs.to(device)\n",
    "                else:\n",
    "                    labels = gen_labs.to(device)        \n",
    "            images = images.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _output, emb = surrogate_model(images)\n",
    "\n",
    "            logits, feature = priv_model(images, emb)\n",
    "            outputs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            labs_pred = np.concatenate((labs_pred, predicted.detach().cpu().numpy()), axis=0 )\n",
    "            labs_raw = np.concatenate((labs_raw, torch.argmax(labels, dim=1).detach().cpu().numpy()), axis=0)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == torch.argmax(labels, dim=1)).sum().item()\n",
    "    print(\"Dataset:\", args.dataset)\n",
    "    if pub_attr:\n",
    "        print(\"Public Attr: Activity\")\n",
    "    else:\n",
    "        print(\"Private Attr:\", args.private)\n",
    "    print(f'Test Accuracy: {100 * correct / total} %')\n",
    "    print_accu_confmat_f1score(Y_true=labs_raw, Y_pred=labs_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e106e8-8736-40c4-bc07-5e26d164898d",
   "metadata": {},
   "outputs": [],
   "source": [
    "surrogate_model.eval()\n",
    "\n",
    "# to disentangle pub & priv attr\n",
    "t = T(x_dim=args.num_public_attr, z_dim=diff_args.cdim).to(device)\n",
    "mi_estimator = Mine(t, loss='mine').to(device)\n",
    "\n",
    "priv_classifier = Aux_Priv_Classifier(args.num_private_attr, diff_args.cdim)    \n",
    "priv_classifier = priv_classifier.to(device)\n",
    "\n",
    "optimizer_priv = Adam(priv_classifier.parameters(), lr=2e-4)\n",
    "optimizer_mine = Adam(mi_estimator.parameters(), lr=2e-4)\n",
    "\n",
    "PATH_PRIV = diff_args.moddir+'/priv_classifier_'+args.dataset+'_'+args.private+'_'+str(trial)+'.pt'\n",
    "print(PATH_PRIV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15754a38-fb89-4232-9a63-ef8653f9e317",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_priv = True\n",
    "train_priv = False\n",
    "\n",
    "w3 = 4\n",
    "if args.dataset == 'mobi':\n",
    "    priv_epochs = 20\n",
    "    w3 = 8\n",
    "elif args.dataset == 'wifi':\n",
    "    priv_epochs = 20\n",
    "elif args.dataset == 'motion':\n",
    "    priv_epochs = 80\n",
    "    \n",
    "if train_priv:\n",
    "    train_priv_classifier(priv_classifier, surrogate_model, priv_train_loader, optimizer_priv, optimizer_mine, mi_estimator, w3, priv_epochs, PATH_PRIV, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4853d9a-da50-4b2c-ba9a-e203c64ca018",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not train_priv:\n",
    "    priv_classifier.load_state_dict(torch.load(PATH_PRIV, map_location=torch.device('cpu')))\n",
    "    priv_classifier.to(device)\n",
    "eval_priv_classifier(args, priv_classifier, surrogate_model, surrogate_test_loader, False, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aad64a-66c0-4199-9dfe-3dcb40b490b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune privacy-utility trade-off post training\n",
    "diff_args.w1 = 7.8\n",
    "diff_args.w2 = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a872c1-681c-47cc-972b-5d2d06374e61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_test_imgs = None\n",
    "recon_test_imgs = None\n",
    "act_test_labs = None\n",
    "priv_test_labs = None\n",
    "weight_test_labs = None\n",
    "is_first_batch = True\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in surrogate_test_loader:\n",
    "        if args.dataset == 'mobi':\n",
    "            images, labels, priv_labels, labels_weight = data\n",
    "            if args.private == 'gender':\n",
    "                priv_labels = priv_labels.to(device)\n",
    "            elif args.private == 'weight':\n",
    "                labels_weight = labels_weight.to(device)\n",
    "        elif args.dataset == 'wifi':\n",
    "            images, labels, priv_labels, labels_weight = data\n",
    "            if args.private == 'height':\n",
    "                priv_labels = priv_labels.to(device)\n",
    "            elif args.private == 'weight':\n",
    "                labels_weight = labels_weight.to(device)\n",
    "        elif args.dataset == 'motion':\n",
    "            images, labels, priv_labels = data\n",
    "            \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)    \n",
    "\n",
    "        _output, emb = surrogate_model(images)\n",
    "        emb = emb.detach()       \n",
    "        cemb = cemblayer(emb)\n",
    "        \n",
    "        if args.dataset == 'mobi':\n",
    "            genshape = (args.batch_size, 1, 6, 128)\n",
    "        elif args.dataset =='wifi':\n",
    "            genshape = (args.batch_size , 1, 90, 80)\n",
    "        elif args.dataset =='motion':\n",
    "            genshape = (args.batch_size , 1, 2, 128)\n",
    "\n",
    "        sample_priv_labels = torch.argmax(priv_labels, dim=1)\n",
    "        if args.dataset == 'mobi':\n",
    "            if args.private == 'weight':\n",
    "                sample_priv_labels = torch.argmax(labels_weight, dim=1)\n",
    "        elif args.dataset == 'wifi':\n",
    "            if args.private == 'weight':\n",
    "                sample_priv_labels = torch.argmax(labels_weight, dim=1)\n",
    "\n",
    "        if diff_args.ddim:\n",
    "            generated = diffusion.ddim_sample(genshape, diff_args.num_steps, diff_args.eta, diff_args.select, priv_classifier=priv_classifier, priv_y=sample_priv_labels, emb=emb, w1=diff_args.w1, w2=diff_args.w2, cemb = cemb)\n",
    "        else:\n",
    "            raise ValueError('DDPM version of PrivDiffuser not implemented.')\n",
    "\n",
    "        synthesized_img = generated\n",
    "        \n",
    "        if is_first_batch:\n",
    "            raw_test_imgs = images.detach().cpu().numpy()\n",
    "            recon_test_imgs = synthesized_img.detach().cpu().numpy()\n",
    "            act_test_labs = labels.detach().cpu().numpy()\n",
    "            if args.dataset != 'motion':\n",
    "                weight_test_labs = labels_weight.detach().cpu().numpy()\n",
    "            priv_test_labs = priv_labels.detach().cpu().numpy()\n",
    "            is_first_batch = False\n",
    "        else:\n",
    "            raw_test_imgs = np.concatenate((raw_test_imgs, images.detach().cpu().numpy()), axis=0)\n",
    "            recon_test_imgs = np.concatenate((recon_test_imgs, synthesized_img.detach().cpu().numpy()), axis=0)    \n",
    "            act_test_labs = np.concatenate((act_test_labs, labels.detach().cpu().numpy()), axis=0)\n",
    "            if args.dataset != 'motion':\n",
    "                weight_test_labs = np.concatenate((weight_test_labs, labels_weight.detach().cpu().numpy()), axis=0)\n",
    "            priv_test_labs = np.concatenate((priv_test_labs, priv_labels.detach().cpu().numpy()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ee2eb7-39b5-489d-95f5-2b66448c262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MSE between obfuscated data and raw data\n",
    "num_eval_pics = raw_test_imgs.shape[0]\n",
    "mse = mean_squared_error(y_true=raw_test_imgs.reshape(num_eval_pics,-1), y_pred=recon_test_imgs.reshape(num_eval_pics,-1))\n",
    "print(\"mse of %d synthesized images: \\n%f\" % (num_eval_pics, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063bb616-ce75-4ff0-99b8-194938c707c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize raw data & reconstructed data\n",
    "plot_comparison = False\n",
    "if plot_comparison:\n",
    "    plot_compare(raw_test_imgs, recon_test_imgs, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb947cf-9539-4cc4-8dce-dc62fc19d528",
   "metadata": {},
   "source": [
    "## Evaluate Privacy & Utility Loss on obfuscated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71fc31b-8ee5-42bb-97bc-03bfa8cb537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tensorflow.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a575c-d6e1-4ef2-a3bd-574e8c3820dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load HAR model & intrusive inference model\n",
    "path_eval = \"./eval_models/\"\n",
    "if args.dataset == 'mobi':\n",
    "    eval_act_model = load_model(path_eval + \"MobiAct/activity_model_DC.hdf5\")\n",
    "    eval_gender_model = load_model(path_eval + \"MobiAct/gender_model_DC.hdf5\")\n",
    "    eval_weight_model = load_model(path_eval + \"MobiAct/weight_model_DC.hdf5\")\n",
    "elif args.dataset == 'motion':\n",
    "    eval_act_model = load_model(path_eval + \"MotionSense/activity_model_mlp.hdf5\")\n",
    "    eval_gender_model = load_model(path_eval + \"MotionSense/gender_model_mlp.hdf5\")\n",
    "elif args.dataset == 'wifi':\n",
    "    eval_act_model = load_model(path_eval + \"WiFi-HAR/wifi_activity_model_sit_80.hdf5\")\n",
    "    eval_weight_model = load_model(path_eval + \"WiFi-HAR/wifi_weight_model_sit_80.hdf5\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e5bd08-92eb-4ef2-9c45-0243d9d0807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.dataset == 'mobi':\n",
    "    public_txt_labels = [\"wlk\", \"std\", \"jog\", \"ups\"]\n",
    "elif args.dataset =='motion':\n",
    "    public_txt_labels = [\"dws\", \"ups\", \"wlk\", \"jog\"]\n",
    "    \n",
    "if args.private == 'gender':\n",
    "    private_txt_labels = [\"m\", \"f\"]\n",
    "elif args.private == 'weight':\n",
    "    private_txt_labels = [\"<=70\", \"70-90\", \">90\"]\n",
    "weight_txt_labels = [\"<=70\", \"70-90\", \">90\"]\n",
    "\n",
    "if args.dataset == 'wifi':\n",
    "    public_txt_labels = [\"sit\", \"fall\", \"lie\", \"std\"]\n",
    "    if args.private == 'weight':\n",
    "        private_txt_labels = [\"<=80\", \">80\"]\n",
    "    elif args.private == 'height':\n",
    "        private_txt_labels = [\"<=175\", \">175\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25f538-b9b9-4056-9dc7-89e3d618b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format obfuscated data\n",
    "if args.dataset == 'mobi':\n",
    "    synthesized_dataset = np.reshape(recon_test_imgs, (recon_test_imgs.shape[0], 6, 128, 1))\n",
    "elif args.dataset == 'wifi':\n",
    "    synthesized_dataset = np.reshape(recon_test_imgs, (recon_test_imgs.shape[0], 90, 80, 1))\n",
    "elif args.dataset == 'motion':\n",
    "    synthesized_dataset = np.reshape(recon_test_imgs, (recon_test_imgs.shape[0], 256))\n",
    "synthesized_act_labels = act_test_labs\n",
    "synthesized_private_labels = priv_test_labs\n",
    "synthesized_weight_labels = weight_test_labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d36ba0-ac56-429a-9fec-8e064d81ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save obfuscated data\n",
    "np.save(diff_args.moddir + '/synthesized_dataset_ddim.npy', synthesized_dataset)\n",
    "np.save(diff_args.moddir + '/raw_test_imgs_ddim.npy', raw_test_imgs)\n",
    "np.save(diff_args.moddir + '/synthesized_act_labels_ddim.npy', synthesized_act_labels)\n",
    "np.save(diff_args.moddir + '/synthesized_private_labels_ddim.npy', synthesized_private_labels)\n",
    "np.save(diff_args.moddir + '/synthesized_weight_labels_ddim.npy', synthesized_weight_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcf472e-06f5-48f7-b344-f1d533db5ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load obfuscated data\n",
    "# synthesized_dataset = np.load(diff_args.moddir + '/synthesized_dataset_ddim.npy') # save\n",
    "# raw_test_imgs = np.load(diff_args.moddir + '/raw_test_imgs_ddim.npy')\n",
    "# synthesized_act_labels = np.load(diff_args.moddir + '/synthesized_act_labels_ddim.npy') # save\n",
    "# synthesized_private_labels = np.load(diff_args.moddir + '/synthesized_private_labels_ddim.npy') # save\n",
    "# synthesized_weight_labels = np.load(diff_args.moddir + '/synthesized_weight_labels_ddim.npy') # save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c4396f-860d-4fc9-b8d6-c578358f999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Activity Identification:\")\n",
    "Y_act = eval_act_model.predict(synthesized_dataset, verbose=args.verbose)\n",
    "Y_act_labels = np.argmax(Y_act, axis=1)  # generate predicted vector of labels\n",
    "pred_act = to_categorical(Y_act_labels, num_classes=args.num_public_attr)\n",
    "print_accu_score(Y_true=synthesized_act_labels, Y_pred=pred_act)\n",
    "print_accu_confmat_f1score(Y_true=np.argmax(synthesized_act_labels, axis=1), Y_pred=Y_act_labels, txt_labels=public_txt_labels)\n",
    "\n",
    "if args.dataset == 'mobi':\n",
    "    print(\"Gender Identification:\")\n",
    "    Y_gen = eval_gender_model.predict(synthesized_dataset, verbose=args.verbose)\n",
    "    Y_gen_labels = np.where(Y_gen > 0.5, 1, 0)\n",
    "    pred_gen = to_categorical(Y_gen_labels, num_classes=2)        \n",
    "    print_accu_score(Y_true=synthesized_private_labels, Y_pred=pred_gen)\n",
    "    print_accu_confmat_f1score(Y_true=np.argmax(synthesized_private_labels, axis=1), Y_pred=Y_gen_labels, txt_labels=private_txt_labels)\n",
    "\n",
    "    print(\"Weight Identification:\")\n",
    "    Y_gen = eval_weight_model.predict(synthesized_dataset, verbose=args.verbose)\n",
    "    Y_gen_labels = np.argmax(Y_gen, axis=1)\n",
    "    pred_gen = to_categorical(Y_gen_labels, num_classes=3)        \n",
    "    print_accu_score(Y_true=synthesized_weight_labels, Y_pred=pred_gen)\n",
    "    print_accu_confmat_f1score(Y_true=np.argmax(synthesized_weight_labels, axis=1), Y_pred=Y_gen_labels, txt_labels=weight_txt_labels)\n",
    "\n",
    "elif args.dataset == 'motion':\n",
    "    print(\"Gender Identification:\")\n",
    "    Y_gen = eval_gender_model.predict(synthesized_dataset, verbose=args.verbose)\n",
    "    Y_gen_labels = np.where(Y_gen > 0.5, 1, 0)\n",
    "    pred_gen = to_categorical(Y_gen_labels, num_classes=args.num_private_attr)        \n",
    "    print_accu_score(Y_true=synthesized_private_labels, Y_pred=pred_gen)\n",
    "    print_accu_confmat_f1score(Y_true=np.argmax(synthesized_private_labels, axis=1), Y_pred=Y_gen_labels, txt_labels=private_txt_labels)\n",
    "\n",
    "elif args.dataset == 'wifi':\n",
    "    print(\"Weight Identification:\")\n",
    "    Y_gen = eval_weight_model.predict(synthesized_dataset, verbose=args.verbose)\n",
    "    Y_gen_labels = np.argmax(Y_gen, axis=1)\n",
    "    pred_gen = to_categorical(Y_gen_labels, num_classes=2)  \n",
    "    print_accu_score(Y_true=synthesized_weight_labels, Y_pred=pred_gen)\n",
    "    print_accu_confmat_f1score(Y_true=np.argmax(synthesized_weight_labels, axis=1), Y_pred=Y_gen_labels, txt_labels=weight_txt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e9e2c-fda6-418d-a738-eccaddc1f87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d00ab5-40ad-448f-8d6d-2d0d90efd111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
